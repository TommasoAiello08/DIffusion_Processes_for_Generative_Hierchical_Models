{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db36b11",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4273772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.grammar import HierarchicalGrammar, encode_dataset, prepare_tensors\n",
    "from configs.grammars import BINARY_3_LEVEL_GRAMMAR, get_leaf_alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2844e",
   "metadata": {},
   "source": [
    "## 2. Define a Hierarchical Grammar\n",
    "\n",
    "We'll use a simple 3-level binary grammar with 4 root symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3306cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the grammar structure\n",
    "print(\"Root symbols:\", BINARY_3_LEVEL_GRAMMAR['root_symbols'])\n",
    "print(\"Terminal symbols:\", BINARY_3_LEVEL_GRAMMAR['terminal_symbols'])\n",
    "print(\"\\nExample production rules:\")\n",
    "for symbol, rules in list(BINARY_3_LEVEL_GRAMMAR['rules'].items())[:3]:\n",
    "    print(f\"  {symbol} -> {rules}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282c889",
   "metadata": {},
   "source": [
    "## 3. Generate Samples\n",
    "\n",
    "Create a grammar instance and generate hierarchical sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize grammar\n",
    "grammar = HierarchicalGrammar(BINARY_3_LEVEL_GRAMMAR)\n",
    "\n",
    "# Generate dataset\n",
    "n_samples = 1000\n",
    "df = grammar.generate_dataset(n_samples=n_samples)\n",
    "\n",
    "print(f\"Generated {len(df)} samples\")\n",
    "print(f\"\\nFirst 5 samples:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf3414",
   "metadata": {},
   "source": [
    "## 4. Analyze the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution\n",
    "print(\"Label distribution:\")\n",
    "print(df['label'].value_counts().sort_index())\n",
    "\n",
    "# Visualize\n",
    "df['label'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Distribution of Root Symbols')\n",
    "plt.xlabel('Root Symbol')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea2502",
   "metadata": {},
   "source": [
    "## 5. Encode Data as One-Hot\n",
    "\n",
    "Convert string sequences to one-hot encoded matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506199cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get leaf alphabet\n",
    "leaf_alphabet = get_leaf_alphabet(BINARY_3_LEVEL_GRAMMAR)\n",
    "print(\"Leaf alphabet:\", leaf_alphabet)\n",
    "\n",
    "# Encode dataset\n",
    "df_encoded = encode_dataset(df.copy(), leaf_alphabet)\n",
    "\n",
    "print(f\"\\nOriginal sequence: {df.iloc[0]['sequence']}\")\n",
    "print(f\"Encoded shape: {df_encoded.iloc[0]['sequence'].shape}\")\n",
    "print(f\"(vocabulary_size, sequence_length) = {df_encoded.iloc[0]['sequence'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec63e3",
   "metadata": {},
   "source": [
    "## 6. Prepare PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eadaf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "data_tensor, label_tensor = prepare_tensors(df_encoded)\n",
    "\n",
    "print(\"Data tensor shape:\", data_tensor.shape)\n",
    "print(\"Label tensor shape:\", label_tensor.shape)\n",
    "print(f\"\\n(batch_size, 1, vocab_size, seq_length) = {data_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ebfce3",
   "metadata": {},
   "source": [
    "## 7. Visualize a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533da6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one-hot encoding of a sample\n",
    "sample_idx = 0\n",
    "sample_matrix = data_tensor[sample_idx, 0, :, :].numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(sample_matrix, cmap='Blues', aspect='auto')\n",
    "plt.colorbar(label='Activation')\n",
    "plt.xlabel('Sequence Position')\n",
    "plt.ylabel('Vocabulary Index')\n",
    "plt.title(f'One-Hot Encoded Sequence (Label: {label_tensor[sample_idx].item()})')\n",
    "plt.yticks(range(len(leaf_alphabet)), leaf_alphabet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70130dec",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you have hierarchical data, you can:\n",
    "1. Apply forward diffusion to add noise\n",
    "2. Train a denoising model\n",
    "3. Evaluate reconstruction accuracy\n",
    "\n",
    "See the other notebooks for these steps!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
